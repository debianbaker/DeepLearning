{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26157c69",
   "metadata": {},
   "source": [
    "# FOR 100 USERS\n",
    "- For 50 users the accuracy is same for both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb25fbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "\n",
    "def resample_emg(single_emg, target_length=1000):\n",
    "    \"\"\"\n",
    "    Resamples EMG signal to a fixed number of time points (target_length).\n",
    "    Assumes input shape is (8, N), returns shape (8, target_length).\n",
    "    \"\"\"\n",
    "    # Get the current length along axis 1\n",
    "    current_length = single_emg.shape[1]\n",
    "    \n",
    "    # Resample with proper up/down parameters\n",
    "    return signal.resample_poly(single_emg, target_length, current_length, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421ce119",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def load_custom_emg_data(dataset_path, max_users=100):\n",
    "    all_emg_data = []\n",
    "    labels = []\n",
    "\n",
    "    for main_folder in ['trainingJSON']:\n",
    "        folder_path = os.path.join(dataset_path, main_folder)\n",
    "\n",
    "        user_folders = [f for f in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, f))]\n",
    "        user_folders = user_folders[:max_users]  # Limit to the first `max_users` folders\n",
    "\n",
    "        for user_folder in user_folders:\n",
    "            user_path = os.path.join(folder_path, user_folder)\n",
    "\n",
    "            for file in os.listdir(user_path):\n",
    "                if file.endswith('.json'):\n",
    "                    json_path = os.path.join(user_path, file)\n",
    "                    with open(json_path, 'r') as f:\n",
    "                        data = json.load(f)\n",
    "\n",
    "                    samples = data.get(\"trainingSamples\", {})\n",
    "                    if(len(samples) == 150):\n",
    "                        for sample in samples.values():\n",
    "                            gesture_name = sample.get(\"gestureName\", \"unknown\")\n",
    "                            emg = sample.get(\"emg\", {})\n",
    "    \n",
    "                            ch_values = [emg.get(f\"ch{i+1}\", []) for i in range(8)]\n",
    "                            if all(len(ch) == len(ch_values[0]) for ch in ch_values):  # sanity check\n",
    "                                if len(ch_values[0]) >= 900:  # assuming your nyquist constraint\n",
    "                                    emg_matrix = np.array(ch_values)\n",
    "                                    resampled_matrix = resample_emg(emg_matrix)\n",
    "                                    all_emg_data.append(resampled_matrix)\n",
    "                                    labels.append(gesture_name)\n",
    "\n",
    "    return all_emg_data, labels\n",
    "\n",
    "# Example usage:\n",
    "dataset_path = '/kaggle/input/emg-dataset/EMG-EPN612 Dataset'\n",
    "emg_data, gesture_labels = load_custom_emg_data(dataset_path, max_users=100)\n",
    "\n",
    "print(f\"Loaded {len(emg_data)} gestures\")\n",
    "print(f\"Unique gestures: {set(gesture_labels)}\")\n",
    "\n",
    "if emg_data:\n",
    "    print(f\"Sample shape: {emg_data[0].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3988e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gesture_to_id = {\n",
    "    \"noGesture\": 0,       # Example: fist = 0\n",
    "    \"fist\": 1,       # open = 1\n",
    "    \"open\": 2,      # pinch = 2\n",
    "    \"waveIn\": 3,    # wave_in = 3\n",
    "    \"pinch\": 4,   # wave_out = 4\n",
    "    \"waveOut\": 5  # no_gesture = 5\n",
    "}\n",
    "# Convert gesture names to numerical IDs\n",
    "label_ids = [gesture_to_id[name] for name in gesture_labels]\n",
    "\n",
    "# Verify\n",
    "print(\"First 150 labels:\", label_ids[:150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c93890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data shape: (7500, 8, 1000)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "\n",
    "def preprocess_emg(single_np_emg, sampling_rate):\n",
    "    \"\"\"\n",
    "    Input: (8, N) - 8 channels, N time points\n",
    "    Output: (8, N) - preprocessed EMG\n",
    "    \"\"\"\n",
    "    # Bandpass filter (20-450 Hz, 4th order Butterworth)\n",
    "    lowcut, highcut = 20.0, 450.0\n",
    "    nyquist = 0.5 * sampling_rate\n",
    "    b, a = signal.butter(4, [lowcut/nyquist, highcut/nyquist], btype='band')\n",
    "    \n",
    "    # Transpose to (N, 8) for filtering\n",
    "    emg_data_t = single_np_emg.T  # (N, 8)\n",
    "    filtered_emg = signal.filtfilt(b, a, emg_data_t, axis=0)\n",
    "    \n",
    "    # Z-score normalization per channel\n",
    "    normalized_emg = (filtered_emg - np.mean(filtered_emg, axis=0)) / (np.std(filtered_emg, axis=0) + 1e-8)\n",
    "    \n",
    "    return normalized_emg.T  # (8, N)\n",
    "\n",
    "def preprocess_all_emg_data(emg_data, sampling_rate=1000):\n",
    "    \"\"\"\n",
    "    Input: (num_samples, 8, N)\n",
    "    Output: (num_samples, 8, N)\n",
    "    \"\"\"\n",
    "    return np.array([preprocess_emg(sample, sampling_rate) for sample in emg_data])\n",
    "\n",
    "# Usage\n",
    "preprocessed_emg = preprocess_all_emg_data(emg_data)\n",
    "print(\"Preprocessed data shape:\", preprocessed_emg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4ba90c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: -2.335169095128246e-20\n",
      "Std: 0.9999999973459965\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean:\", preprocessed_emg.mean())  # Should be ≈0 (normalized)\n",
    "print(\"Std:\", preprocessed_emg.std())   # Should be ≈1 if z-scored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "138fea1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of outliers (>3σ): 0.00%\n"
     ]
    }
   ],
   "source": [
    "preprocessed_emg = np.clip(preprocessed_emg, -3, 3)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(preprocessed_emg.flatten(), bins=50)\n",
    "plt.title(\"Distribution of Preprocessed EMG\")\n",
    "plt.xlabel(\"Amplitude (Z-score)\"); plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "outliers = np.sum(np.abs(preprocessed_emg) > 3) / preprocessed_emg.size * 100\n",
    "print(f\"Percentage of outliers (>3σ): {outliers:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5d9585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STFT Magnitude shape: (7500, 8, 257, 17)\n",
      "Frequencies shape: (257,)\n",
      "Time bins shape: (17,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import stft\n",
    "\n",
    "# Input: preprocessed_emg shape (7500, 8, 1000)\n",
    "n_samples, n_channels, n_points = preprocessed_emg.shape\n",
    "sampling_rate = 1000  # Hz\n",
    "\n",
    "# STFT parameters (adjust based on your needs)\n",
    "nperseg = 256       # Window length (256 ms)\n",
    "noverlap = 192      # Overlap (75%)\n",
    "nfft = 512          # FFT size (zero-padding for better frequency resolution)\n",
    "\n",
    "# Compute STFT for one example to get the output shape\n",
    "f, t, Zxx = stft(\n",
    "    preprocessed_emg[0, 0, :],\n",
    "    fs=sampling_rate,\n",
    "    window='hann',\n",
    "    nperseg=nperseg,\n",
    "    noverlap=noverlap,\n",
    "    nfft=nfft,\n",
    "    return_onesided=True\n",
    ")\n",
    "\n",
    "# Initialize output arrays using the actual dimensions from the test run\n",
    "frequencies = f\n",
    "time_bins = t\n",
    "n_freq_bins = f.shape[0]\n",
    "n_time_bins = t.shape[0]\n",
    "stft_magnitude = np.zeros((n_samples, n_channels, n_freq_bins, n_time_bins))\n",
    "\n",
    "# Compute STFT for all samples and channels\n",
    "for i in range(n_samples):\n",
    "    for j in range(n_channels):\n",
    "        _, _, Zxx = stft(\n",
    "            preprocessed_emg[i, j, :],\n",
    "            fs=sampling_rate,\n",
    "            window='hann',\n",
    "            nperseg=nperseg,\n",
    "            noverlap=noverlap,\n",
    "            nfft=nfft,\n",
    "            return_onesided=True\n",
    "        )\n",
    "        stft_magnitude[i, j] = np.abs(Zxx)  # Store magnitude\n",
    "\n",
    "# Verify shapes\n",
    "print(f\"STFT Magnitude shape: {stft_magnitude.shape}\")  # (7500, 8, 257, 17)\n",
    "print(f\"Frequencies shape: {frequencies.shape}\")        # (257,)\n",
    "print(f\"Time bins shape: {time_bins.shape}\")            # (17,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beec8eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import jit, prange\n",
    "\n",
    "@jit(nopython=True, parallel=True)\n",
    "def compute_band_powers(power_spectrum, frequencies, bands):\n",
    "    \"\"\"\n",
    "    Numba-compatible band power computation without np.mean(axis)\n",
    "    \"\"\"\n",
    "    n_samples, n_channels, n_freqs, n_times = power_spectrum.shape\n",
    "    n_bands = len(bands)\n",
    "    band_features = np.zeros((n_samples, n_channels, n_bands))\n",
    "    \n",
    "    for b in prange(n_bands):  # Parallel loop\n",
    "        low, high = bands[b]\n",
    "        count = 0\n",
    "        \n",
    "        for s in prange(n_samples):\n",
    "            for c in range(n_channels):\n",
    "                total = 0.0\n",
    "                freq_count = 0\n",
    "                \n",
    "                for f in range(n_freqs):\n",
    "                    if low <= frequencies[f] <= high:\n",
    "                        # Manual mean calculation over time axis\n",
    "                        time_sum = 0.0\n",
    "                        for t in range(n_times):\n",
    "                            time_sum += power_spectrum[s, c, f, t]\n",
    "                        total += time_sum / n_times\n",
    "                        freq_count += 1\n",
    "                \n",
    "                if freq_count > 0:\n",
    "                    band_features[s, c, b] = total / freq_count\n",
    "    \n",
    "    return band_features\n",
    "\n",
    "def extract_6class_emg_features_optimized(stft_magnitude, frequencies, fs=1000):\n",
    "    \"\"\"\n",
    "    Fully working version with all fixes applied\n",
    "    \"\"\"\n",
    "    n_samples, n_channels, n_freqs, n_times = stft_magnitude.shape\n",
    "\n",
    "    # 1. Power spectrum (vectorized)\n",
    "    power_spectrum = np.square(stft_magnitude)\n",
    "    total_power = np.sum(power_spectrum, axis=2)  # shape: (n_samples, n_channels, n_times)\n",
    "\n",
    "    # 2. Mean frequency (vectorized)\n",
    "    weighted_sum = np.sum(power_spectrum * frequencies[None, None, :, None], axis=2)\n",
    "    mean_freq = weighted_sum / (total_power + 1e-10)\n",
    "\n",
    "    # 3. Median frequency (fixed broadcasting)\n",
    "    cumsum = np.cumsum(power_spectrum, axis=2)  # shape: (n_samples, n_channels, n_freqs, n_times)\n",
    "    half_power = 0.5 * total_power[:, :, None, :]  # shape: (n_samples, n_channels, 1, n_times)\n",
    "    \n",
    "    # Find median frequency indices\n",
    "    median_freq_idx = np.empty((n_samples, n_channels, n_times), dtype=np.int64)\n",
    "    for s in range(n_samples):\n",
    "        for c in range(n_channels):\n",
    "            for t in range(n_times):\n",
    "                median_freq_idx[s, c, t] = np.argmax(cumsum[s, c, :, t] >= half_power[s, c, 0, t])\n",
    "    \n",
    "    median_freq = frequencies[median_freq_idx]\n",
    "\n",
    "    # 4. Spectral entropy (vectorized)\n",
    "    prob = power_spectrum / (total_power[:, :, None, :] + 1e-10)\n",
    "    entropy = -np.sum(prob * np.log2(prob + 1e-10), axis=2)\n",
    "\n",
    "    # 5. Band powers (using fixed computation)\n",
    "    bands = [(20, 50), (50, 100), (100, 150), (150, 250), (250, 350), (350, 500)]\n",
    "    band_powers = compute_band_powers(power_spectrum, frequencies, bands)\n",
    "\n",
    "    # 6. Time aggregation\n",
    "    features = np.stack([mean_freq, median_freq, total_power, entropy], axis=-1)\n",
    "    features_mean = np.mean(features, axis=2)\n",
    "    features_std = np.std(features, axis=2)\n",
    "\n",
    "    # 7. Channel correlations (vectorized)\n",
    "    stft_db = 20 * np.log10(stft_magnitude + 1e-10)\n",
    "    stft_flat = stft_db.reshape(n_samples, n_channels, -1)\n",
    "    corr_features = np.zeros((n_samples, n_channels * (n_channels - 1) // 2))\n",
    "    \n",
    "    for s in range(n_samples):\n",
    "        corr_matrix = np.corrcoef(stft_flat[s])\n",
    "        corr_features[s] = corr_matrix[np.triu_indices(n_channels, k=1)]\n",
    "\n",
    "    # 8. Final feature matrix\n",
    "    X = np.hstack([\n",
    "        features_mean.reshape(n_samples, -1),\n",
    "        features_std.reshape(n_samples, -1),\n",
    "        band_powers.reshape(n_samples, -1),\n",
    "        corr_features\n",
    "    ])\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd173653",
   "metadata": {},
   "outputs": [],
   "source": [
    "stft_magnitude = np.load(\"./variables/stft_magnitude.npy\")\n",
    "frequencies = np.load(\"./variables/frequencies.npy\")\n",
    "\n",
    "features = extract_6class_emg_features_optimized(stft_magnitude, frequencies, fs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08c7a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69a4882",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = label_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d1496d",
   "metadata": {},
   "source": [
    "# MODEL 1 - 89% Accuracy - RF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0731ab41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features,  # or X_reduced if using feature selection\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d27a167",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Test accuracy:\", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d7a333",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8834918e",
   "metadata": {},
   "source": [
    "# MODEL 2 - 92.01% Accuracy (1D CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7383b614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Reshape features to (samples, timesteps, channels)\n",
    "X_reshaped = features.reshape(-1, 140, 1)  # Treat each feature as a timestep\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_onehot = to_categorical(y)  # Assuming y contains class indices 0-5\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_reshaped, y_onehot, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f217852a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Flatten, scale, then reshape back\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.reshape(-1, 140)).reshape(-1, 140, 1)\n",
    "X_test_scaled = scaler.transform(X_test.reshape(-1, 140)).reshape(-1, 140, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabd4a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv1D, MaxPooling1D,\n",
    "    BatchNormalization,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    Dense\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "model = Sequential([\n",
    "    # Feature extraction block\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(140, 1)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    # Second convolution block\n",
    "    Conv1D(128, kernel_size=3, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.4),\n",
    "    \n",
    "    # Classifier\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(6, activation='softmax')  # 6 gesture classes\n",
    "])\n",
    "\n",
    "# Compile with custom learning rate\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0005),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=15, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(factor=0.5, patience=5)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaeefe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_data=(X_test_scaled, y_test),\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "test_loss, test_acc = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "print(f\"\\nTest Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3711d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get predictions (convert from one-hot to class indices)\n",
    "y_pred = model.predict(X_test_scaled).argmax(axis=1)\n",
    "y_true = y_test.argmax(axis=1)\n",
    "\n",
    "# Generate and plot confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, \n",
    "                            display_labels=[\"noGesture\", \"fist\", \"open\", \"waveIn\", \"pinch\", \"waveOut\"])\n",
    "disp.plot(cmap='Blues', xticks_rotation=45)\n",
    "plt.title('EMG Gesture Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
