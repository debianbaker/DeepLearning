{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bff9133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7500, 128)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.load('../train_data/train_feature_matrix.npy')\n",
    "y = np.load(\"../train_data/train_gesture_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee97ecde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (Conv1D, MaxPooling1D, Flatten, \n",
    "                                    Dense, Dropout, BatchNormalization)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "X = np.load('../train_data/train_feature_matrix.npy')\n",
    "y = np.load(\"../train_data/train_gesture_labels.npy\")\n",
    "\n",
    "# Verify data\n",
    "print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
    "print(\"Class distribution:\", np.bincount(y))\n",
    "\n",
    "# Preprocessing\n",
    "X = np.nan_to_num(X)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Better Feature Selection - Use mutual information\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Get top 384 features (reduced from 512 to prevent overfitting)\n",
    "print(\"Selecting best features...\")\n",
    "mi_scores = mutual_info_classif(X_scaled, y, random_state=42)\n",
    "top_features_idx = np.argsort(mi_scores)[-384:]  # Using 384 features (64x6)\n",
    "X_selected = X_scaled[:, top_features_idx]\n",
    "\n",
    "# Reshape to (samples, 64, 6) - better than (64,8)\n",
    "X_reshaped = X_selected.reshape(-1, 64, 6)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_reshaped, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 6)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 6)\n",
    "\n",
    "# Optimized CNN Model\n",
    "def build_optimized_cnn():\n",
    "    model = Sequential([\n",
    "        # Conv Block 1\n",
    "        Conv1D(64, 5, activation='relu', input_shape=(64, 6), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(2),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        # Conv Block 2\n",
    "        Conv1D(128, 5, activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(2),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        # Conv Block 3\n",
    "        Conv1D(256, 3, activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(2),\n",
    "        Dropout(0.4),\n",
    "        \n",
    "        Flatten(),\n",
    "        \n",
    "        # Dense layers\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        \n",
    "        Dense(6, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    optimizer = Adam(learning_rate=0.00075)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = build_optimized_cnn()\n",
    "model.summary()\n",
    "\n",
    "# Enhanced callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=12, monitor='val_accuracy', \n",
    "                 restore_best_weights=True, min_delta=0.001),\n",
    "    ReduceLROnPlateau(factor=0.2, patience=6, min_lr=1e-6)\n",
    "]\n",
    "\n",
    "# Training\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=80,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"\\nTest Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f60f59ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature statistics:\n",
      "               0            1            2            3            4    \\\n",
      "count  7500.000000  7500.000000  7500.000000  7500.000000  7500.000000   \n",
      "mean      0.036374    38.155156     2.302027     0.764887     0.035192   \n",
      "std       0.013591     2.828549     0.000407     0.035307     0.014225   \n",
      "min       0.005167    29.296875     2.298264     0.607000     0.006414   \n",
      "25%       0.027108    35.937500     2.301877     0.741000     0.025549   \n",
      "50%       0.033248    37.890625     2.302128     0.765000     0.031604   \n",
      "75%       0.042682    40.625000     2.302296     0.791000     0.040492   \n",
      "max       0.126178    44.531250     2.302575     0.865000     0.139137   \n",
      "\n",
      "               5            6            7            8            9    ...  \\\n",
      "count  7500.000000  7500.000000  7500.000000  7500.000000  7500.000000  ...   \n",
      "mean     33.004740     2.301947     0.651065     0.029273    24.975729  ...   \n",
      "std       2.872149     0.000456     0.043059     0.013923     4.261392  ...   \n",
      "min      17.578125     2.296791     0.390000     0.006253    11.718750  ...   \n",
      "25%      31.640625     2.301780     0.623000     0.020730    21.484375  ...   \n",
      "50%      33.203125     2.302057     0.651000     0.025958    25.781250  ...   \n",
      "75%      34.765625     2.302245     0.682000     0.033902    28.125000  ...   \n",
      "max      39.843750     2.302585     0.787000     0.565879    34.375000  ...   \n",
      "\n",
      "               118          119          120          121          122  \\\n",
      "count  7500.000000  7500.000000  7500.000000  7500.000000  7500.000000   \n",
      "mean      2.301931     0.652583     0.028997    24.907656     2.301441   \n",
      "std       0.000470     0.044782     0.012698     4.293907     0.000806   \n",
      "min       2.296379     0.373000     0.005131    10.937500     2.292876   \n",
      "25%       2.301771     0.624000     0.020340    21.484375     2.301109   \n",
      "50%       2.302044     0.652000     0.025653    23.828125     2.301636   \n",
      "75%       2.302235     0.685000     0.033350    28.125000     2.302000   \n",
      "max       2.302585     0.777000     0.084549    34.375000     2.302565   \n",
      "\n",
      "               123          124          125          126          127  \n",
      "count  7500.000000  7500.000000  7500.000000  7500.000000  7500.000000  \n",
      "mean      0.503216     0.031992    18.457708     2.295063     0.370819  \n",
      "std       0.065724     0.031284     3.272928     0.094856     0.060382  \n",
      "min       0.266000     0.005194     3.125000     0.276980     0.000000  \n",
      "25%       0.456000     0.020849    16.406250     2.300285     0.337000  \n",
      "50%       0.496000     0.025734    18.359375     2.301149     0.368000  \n",
      "75%       0.551000     0.033505    20.703125     2.301661     0.404000  \n",
      "max       0.676000     0.608719    28.906250     2.302575     0.542000  \n",
      "\n",
      "[8 rows x 128 columns]\n"
     ]
    }
   ],
   "source": [
    "# Look for strange values\n",
    "import pandas as pd\n",
    "print(\"Feature statistics:\")\n",
    "print(pd.DataFrame(X).describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
